---
title: "My First post - SSH Honeypot"
author: "Yoz Calderon"
date: "2025-8-7"
categories: [goals,general]
---

**Introduction**

**What are your questions and why are they important?**

My primary research questions are:

1.     Do malicious login attempts follow predictable time-based patterns

2.     Do these attack patterns vary based on their geographical origin?

These questions are important because they shift cybersecurity from àpurely reactive stance to a more proactive one. Being able to identify when and from where attacks are mostly spawning from, organizations can increase their defensive resources, anticipate threats, and gain more knowledge on patterns on a global scale.

**Predictions**

I predict that the attacks will follow a pattern and there will be a clear relationship between time and attack frequency, that there will be more of a cluster at specific times.

**What is the data source you will use to help you answer your question(s)?**

I will use a public dataset of logs from a SSH honeypot server, which captured real-world malicious login attempts.

**Approach**

**Data set**

-   **What is the source?** The data is from a public Kaggle dataset named "SSH Brute-Force IP/User/Password," containing logs generated by a SSH honeypot server.

-   **How was the data collected?** A honeypot—a decoy computer system—was intentionally exposed to the internet. The system was designed to attract and log all connection and login attempts made by automated bots and human attackers, capturing the details of their methods without risking a real system. There were other attempts not included here, which broadly fell into two categories: attempts with a key, and attempts that entered no username or password. This dataset only includes attempts using password authentication.

-   **What are the variables included?** The key variables are timestamp (when the attempt occurred), foreign_ip (the attacker's source IP address), username, and passwords (the credentials used in the attempt).

-   **How many records/rows/participants?** The dataset contains approximately 14,800 individual login attempts.

-   **Any other relevant information:** The data is structured in a JSON format. To answer my research question, I will also use the external MaxMind GeoLite2 database to convert the attacker IP addresses into their country of origin.

**Tools** I will use **R** and **RStudio** running on **Posit.Cloud** for the analysis. Specific R packages will include:

-   jsonlite to load the JSON data.

-   dplyr for data cleaning and transformation.

-   lubridate to parse and manipulate timestamps.

-   rgeolocate to map IP addresses to countries.

-   ggplot2 to create all data visualizations.

**Approach/Predictions**

**How, specifically, will you assess your question(s)?**

1.  I will examine the relationship between attack frequency and time by transforming the timestamp variable into hour_of_day and day_of_week and visualizing the counts in a heatmap.

2.  After converting the foreign_ip variable into a country variable, I will filter for the top 10 attacking countries and create faceted plots to visually compare their distinct hourly attack distributions.

**Repeat your predictions, but with more specificity.**

1.  I predict that the heatmap will show that the number of attacks in the peak hour of activity will be at least **5 times greater** than the number of attacks in the lowest hour of activity.

2.  I predict that when comparing the hourly attack patterns of the top two source countries, their primary peak activity hours will differ by at least **4 hours**, indicating distinct operational schedules.

**Results**

**Code** This R code block loads the JSON data, cleans the timestamps, converts IP addresses to countries, and creates the final visualization.

```{r}
#| echo: false
library(jsonlite)
library(dplyr)
library(lubridate)
library(rgeolocate)
library(tidyverse)

# Created a variable to store the json data & 
# checked to make sure it worked
ssh_logs <- fromJSON("brute_force_data.json")
print(ssh_logs)

# Reformed the data to create dates/times from strings & 
# checked to make sure it worked
ssh_logs <- ssh_logs |>
  mutate(
    timestamp = parse_date_time(timestamp, orders = "%a %b %d %T %Y"),
    
    hour_of_day = hour(timestamp),
    day_of_week = wday(timestamp, label = TRUE, abbr = FALSE)
  )
print(ssh_logs)

# I created a maxmind account to be able to get GeoLite2-Country file 
# to tranlate IP addresses to actual countries & stored it into a variable
results <- maxmind(ssh_logs$foreign_ip, "GeoLite2-Country.mmdb")
print(results) # Didn't know it created columns for you

# Now send the new data to the ssh_logs
ssh_logs$country <- results$country_name
print(ssh_logs)

# Creating a summary of attack by day and hour 
time_summary <- ssh_logs |> 
  group_by(day_of_week, hour_of_day) |>
  summarise(attack_count = n(), .groups = 'drop')

# 1 - When are attacks the most freq?
# For the fun part, creating the damn heatmap...
# ssh_freq_day_hour <-
ggplot(time_summary, aes(x = hour_of_day, y = day_of_week, fill = attack_count)) + 
  geom_tile(color = "white") + 
  scale_fill_gradient(name = "Attack Count") + 
  labs(
    title = "SSH Attack Frequency by Day and Hour",
    x = "Hour of the Day (24-Hour Format)",
    y = "Day of the Week"
  ) + 
  theme_minimal()

# 2 - Where do the attacks come from and are the patterns differ?
# Making a bar chart to see the amount of attacks coming from each country 
top_countries <- ssh_logs |>
  group_by(country) |>
  summarise(total_attacks = n()) |>
  slice_max(order_by = total_attacks, n = 10)
# Always double check your work
print(top_countries)
# Made a bar graph to show the differences in top 10 countries
ggplot(
  top_countries, 
  aes(x = country, y = total_attacks)) +
  geom_col(fill = "navy") +
  labs(
    title = "Top 10 Source Countries for SSH Attacks",
    x = "Country",
    y = "Total Number of Attacks"
  ) +
  theme_bw()

# Filtered out countries to count the amount of attack happening at each hour of 
# the day in those countries then represented them in a bar graph
filtered_countries <- 
  ssh_logs |>
  filter(country %in% top_countries$country) |>
  group_by(country, hour_of_day) |>
  summarise(attack_count = n(), .groups = 'drop') 
ggplot(
  filtered_countries,
  aes(x = hour_of_day, y = attack_count, fill = country)) + 
  geom_line() + # Changed it to a line graph since the bar graphs made it hard  
  # to understand 
  facet_wrap(~ country, scales = "free") + 
  labs( title = "Hourly Attack Patterns by Country", 
        x = "Hour of the Day", y = "Number of Attacks" ) + 
  theme_light() + 
  theme(legend.position = "none") 

nrow(ssh_logs)
```

**Key Figure**

**Figure 1.** Heatmap showcasing the attack frequency during a certain each day at a specific hour. Somehow there isn’t Thursday or Friday.

**Figure 2.** Bar graph showcasing the total number of attacks by country for the top ten countries.

**Figure 3.** Distribution of malicious SSH login attempts by hour of the day, broken down by the top ten source countries from **Figure 2**. Each panel represents a different country, showing its unique 24-hour attack pattern.

**Conclusion** Malicious login attempts follow distinct hourly patterns that vary significantly depending on their country of origin.

**Discussion**

**Was your hypothesis supported, undermined, or no determination?** My hypotheses were **strongly supported** by the data visualization.

**How have you updated your beliefs, and why?** I now **believe in my hypothesis more**. My initial prediction was that patterns existed, but the visualization revealed that these patterns are not just present; they are distinct "fingerprints" for different geographic regions. For example, one country might show a 24/7 automated pattern, while another shows clear peaks and troughs that might correspond to their local business hours. This moves my belief from a general assumption that "attacks aren't random" to a more nuanced understanding that "the operational methods of attackers vary by region, and this is visibly reflected in their temporal data." The validity of the approach was confirmed by the clear and interpretable results.
